source,target,tgt_lng
Token Budget,令牌预算,
Sequence Length,序列长度,
Vision-Language Alignment,视觉语言对齐,
Merger,合并,
67B,67B,
"8,192",8192,
Multimodal Pre-Training,多模态预训练,
All,全部,
~1T,~1T,
Opus 4.1,Opus 4.1,
Hypersim,Hypersim,
SUNRGBD,SUNRGBD,
OSWorld,OSWorld,
WindowsAA,WindowsAA,
CountBench,CountBench,
ODinW-13,ODinW-13,
ARKitScenes,ARKitScenes,
Charades-STA,Charades-STA,
mIoU,mIoU,
VideoMMMU,VideoMMMU,
MMVU,MMVU,
Embodied/Spatial,具身/空间,
Understanding,理解,
ERQA,ERQA,
VSI-Bench,VSI-Bench,
OSWorldG,OSWorldG,
AndroidWorld,AndroidWorld,
Perception,感知,
Tool,工具,
V∗,V*,
93.7+,93.7+,
HRBench4K,HRBench4K,
85.4+,85.4+,
HRBench8K,HRBench8K,
MUIRBENCH,MUIRBENCH,
Video,视频,
MVBench,MVBench,
Video-MMEw/o sub.,无子视频MME,
MLVUM-Avg,MLVUM-Avg,
LVBench,LVBench,
MMMU-Pro,MMMU-Pro,
MathVistamini,MathVistamini,
MathVision,MathVision,
MathVisionWP,MathVisionWP,
We-Math,We-Math,
Agent,代理,
ScreenSpot Pro,ScreenSpot Pro,
Qwen3-VL,Qwen3-VL,
235B-A22B,235B-A22B,
Gemini,Gemini,
2.5 Pro,2.5 Pro,
OpenAI,OpenAI,
GPT-5,GPT-5,
Claude,Claude,
visual benchmarks,视觉基准测试,
technical report,技术报告,
tool use,工具使用,
thinking,思考,
instruct,指令,
STEM,STEM,
Puzzle,谜题,
MMMU,MMMU,
RefSpatialBench,RefSpatialBench,
RoboSpatialHome,RoboSpatialHome,
Multi-Image,多图像,
BLINK,BLINK,
EmbSpatialBench,EmbSpatialBench,
70.6∗,70.6∗,
DocVQAtest,DocVQAtest,
InfoVQAtest,InfoVQAtest,
AI2Dw. M.,AI2Dw. M.,
ChartQAtest,ChartQAtest,
OCRBench,OCRBench,
OCRBench_v2zh,OCRBench_v2zh,
CC-OCR,CC-OCR,
OmniDocBench,OmniDocBench,
general visual question answering,通用视觉问答,
MMBench-V1.1,MMBench-V1.1,
RealWorldQA,RealWorldQA,
MMStar,MMStar,
SimpleVQA,SimpleVQA,
Qwen3-VL family,Qwen3-VL系列,
Qwen3-VL-235B-A22B-Thinking,Qwen3-VL-235B-A22B-Thinking,
Gemini-2.5-Pro,Gemini-2.5-Pro,
Qwen3-VL-235B-A22B-Instruct,Qwen3-VL-235B-A22B-Instruct,
Qwen3-VL-32B-Thinking,Qwen3-VL-32B-Thinking,
Qwen3-VL-32B-Instruct,Qwen3-VL-32B-Instruct,
MathVersemini,MathVersemini,
DynaMath,DynaMath,
Math-VR,Math-VR,
64.7*,64.7*,
ZeroBench,ZeroBench,
VlmsAreBlind,VlmsAreBlind,
LogicVista,LogicVista,
VisuLogic,VisuLogic,
VisualPuzzles,VisualPuzzles,
General VQA,通用视觉问答,
MMBench-EN,MMBench-EN,
90.1∗,90.1*,
MMBench-CN,MMBench-CN,
Qwen3-VL-235B-A22B,Qwen3-VL-235B-A22B,
reasoning models,推理模型,
non-reasoning models,非推理模型,
budget-128,预算-128,
high,高,
minimal,最小,
non-thinking,非思考,
OmniDocBenchzh,OmniDocBenchzh,
CharXiv(DQ),CharXiv(DQ),
CharXiv(RQ),CharXiv(RQ),
MMLongBenchDoc,MMLongBenchDoc,
2D/3D,2D/3D,
Grounding,Grounding,
RefCOCO-avg,RefCOCO-avg,
Alignment,对齐,
HallusionBench,HallusionBench,
MM-MT-Bench,MM-MT-Bench,
MIA-Bench,MIA-Bench,
Document,文档,
Multi-Modal,多模态,
GPT-5 nano,GPT-5 nano,
82.5*,82.5*,
with Tool,带工具,
89.5+,89.5+,
91.1+,91.1+,
DeepStack,DeepStack,
Meng et al.,孟等人,
LLM,大语言模型,
Vision Transformer (ViT),视觉Transformer（ViT）,
vision encoder,视觉编码器,
vision–language mergermodules,视觉-语言合并模块,
Qwen2.5-VL,Qwen2.5-VL,
MRoPE,MRoPE,
temporal position IDs,时间位置ID,
videotemporal patch,视频时间块,
timestamp,时间戳,
SigLIP-2,SigLIP-2,
MLP-based vision–language merger,基于MLP的视觉-语言合并,
Qwen3 large language model (LLM),Qwen3大语言模型（LLM）,
pre-training,预训练,
Training Recipe,训练配方,
dynamic resolutions,动态分辨率,
three-module architecture,三模块架构,
Table 1,表1,
Training setup,训练设置,
hyperparameters,超参数,
Embodied/Spatial Understanding,具身/空间理解,
30B-A3B,30B-A3B,
32B,32B,
2.5 Flash,2.5 Flash,
mini,mini,
AI2Dw,AI2Dw,
PolyMATH,PolyMATH,
Strong-to-Weak Distillation approach,强到弱蒸馏方法,
lightweight models,轻量级模型,
Qwen3-VL-32B,Qwen3-VL-32B,
Qwen3-VL-30B-A3B,Qwen3-VL-30B-A3B,
corresponding baselines,对应基线,
75.9+,75.9+,
88.0+,88.0+,
Qwen3-235B-A22B-Thinking-2507,Qwen3-235B-A22B-思考-2507,
OpenAI o3,OpenAI o3,
Creative Writing,创意写作,
WritingBench,WritingBench,
Coding,编程,
LiveCodeBench,LiveCodeBench,
BFCL,BFCL,
Multilingualism,多语制,
MultiIF,MultiIF,
MMLU-ProX,MMLU-ProX,
Qwen3,Qwen3,
Instruct-2507,指令-2507,
Knowledge,知识,
MMLU-Pro,MMLU-Pro,
MMLU-Redux,MMLU-Redux,
1.7B,1.7B,
Thinking-2507,Thinking-2507,
Qwen3-32B,Qwen3-32B,
Qwen3-30B-A3B,Qwen3-30B-A3B,
AIME-25,AIME-25,
HMMT-25,HMMT-25,
Qwen3-30B-A3B-2507,Qwen3-30B-A3B-2507,
Qwen3-VL-2B,Qwen3-VL-2B,
Qwen3-VL-4B,Qwen3-VL-4B,
Qwen3-VL-8B,Qwen3-VL-8B,
GPQA,GPQA,
SuperGPQA,SuperGPQA,
Reasoning,推理,
LiveBench 2024-11-25,LiveBench 2024-11-25,
Tasks,任务,
IFEval,IFEval,
Arena-Hard V2(winrate) 77.4,Arena-Hard V2(胜率) 77.4,
LiveBench,LiveBench,
2024-11-25,2024-11-25,
CFEval,CFEval,
OJBench,OJBench,
Arena-Hard,Arena-Hard,
winrate,胜率,
74.8,74.8,
Design2Code,设计到代码,
rick.jpg,rick.jpg,
Arena-Hard V2(winrate) 64.7,Arena-Hard V2(胜率) 64.7,
Creative Writing v3,创意写作 v3,
Coding & Agent,编程与代理,
pretraining,预训练,
post-training,后训练,
warm-up alignment phase,预热对齐阶段,
merger (vision–language projection) layers,合并层（视觉-语言投影）,
full-parameter training,全参数训练,
context windows,上下文窗口,
32K,32K,
256K,256K,
sequence lengths,序列长度,
supervised fine-tuning,监督微调,
long chain-of-thought data,长思维链数据,
knowledge distillation,知识蒸馏,
stronger teacher models,更强的教师模型,
reinforcement learning,强化学习,
vision–language foundation model,视觉-语言基础模型,
multimodal intelligence,多模态智能,
action,行动,
application domains,应用领域,
model architecture,模型架构,
training framework,训练框架,
text,文本,
vision,视觉,
multimodal reasoning benchmarks,多模态推理基准,
large language model (LLM),大语言模型（LLM）,
Qwen3 backbones,Qwen3主干网络,
Qwen3-VL-2B/4B/8B/32B,Qwen3-VL-2B/4B/8B/32B,
MoE variants,MoE变体,
total parameters,总参数,
activated per token,每个token激活的,
Adaptation-multiple-choice,多选题适应,
Adaptation-open-ended,开放式适应,
Arena-Hard V2 (winrate) 6.4,Arena-Hard V2（胜率）6.4,
LiveCodeBench v6,LiveCodeBench v6,
BFCL-v3,BFCL-v3,
INCLUDE,INCLUDE,
Arena-Hard V2(winrate) 60.5,Arena-Hard V2(胜率) 60.5,
TAU2-Retail,TAU2-Retail,
Qwen3-1.7B,Qwen3-1.7B,
Qwen3-8B,Qwen3-8B,
Qwen3-4B,Qwen3-4B,
Qwen3-4B-2507,Qwen3-4B-2507,
{class_name},{类别名称},
3D bounding boxes,3D边界框,
JSON format,JSON格式,
Qwen3-VL-30B-A3B-Instruct,Qwen3-VL-30B-A3B-Instruct,
Benchmark,基准测试,
MathVista,MathVista,
MathVerse,MathVerse,
GPT-o4-mini,GPT-o4-mini,
LaTeX,LaTeX,
image_zoom_in_tool,图像缩放工具,
bounding box,边界框,
object label,对象标签,
VideoMME,VideoMME,
MLVU,MLVU,
Gemini 2.5 Pro,Gemini 2.5 Pro,
Claude Opus4.1,Claude Opus4.1,
ScreenSpot,ScreenSpot,
function,函数,
open-ended,开放式,
LETTER,字母,
question,问题,
Visual Information,视觉信息,
reasoning process,推理过程,
VLMBlind,VLMBlind,
VisualPuzzles-Direct,VisualPuzzles-Direct,
VisualPuzzles-CoT,VisualPuzzles-CoT,
B.2 GeneralVQA,B.2 GeneralVQA,
MMBench,MMBench,
Perceptionwith Tool,感知工具,
research tools,研究工具,
structured thinking process,结构化思维过程,
iterative loop,迭代循环,
Table Processing,表格处理,
HTML format,HTML格式,
<table>,<table>,
</table>,</table>,
Figure Handling,图形处理,
PDF image,PDF图像,
Markdown document,Markdown文档,
line breaks,换行符,
complex layouts,复杂布局,
original document,原始文档,
accuracy,准确性,
consistency,一致性,
GPT-5-Nano,GPT-5-Nano,
large vision language models,大视觉语言模型,
Claude opus 4.1,Claude opus 4.1,
MIA-Bench-Thinking,MIA-Bench-Thinking,
math,数学,
textual,文本,
OCR,OCR,
document parsing,文档解析,
document question answering,文档问答,
document reasoning,文档推理,
OCR-Bench,OCR-Bench,
OCRBench_v2,OCRBench_v2,
76.0,76.0,
image,图像,
maxItems,最大项,
region,区域,
2D/3D Grounding,2D/3D 定位,
RefCOCO,RefCOCO,
bbox coordinates,边界框坐标,
Options,选项,
instance,实例,
categories,类别,
img_idx,img_idx,
number,数字,
description,描述,
zoomed-in image,缩放图像,
required,必需,
bbox_2d,bbox_2d,
label,标签,
function call,函数调用,
JSON object,JSON对象,
function name,函数名,
arguments,参数,
tool_call,tool_call,
MM MT Bench,MM MT 基准,
B.3 Alignment,B.3 对齐,
B.4 Document-Understanding,B.4 文档理解,
MMLongBench-Doc,MMLongBench-Doc,
DocVQA,DocVQA,
InfoVQA,InfoVQA,
ChartQA_TEST,ChartQA_TEST,
Multilingual OCR,多语言OCR,
self-built test set,自建测试集,
supported languages,支持语言,
state of the art,SOTA,
Qwen3-VL- 235B-A22B-Thinking,Qwen3-VL-235B-A22B-Thinking,
visual question answering (VQA),视觉问答（VQA）,
AI2D,AI2D,
ChartQA,ChartQA,
CharXiv,CharXiv,
Qwen3-VL-30BA3B models,Qwen3-VL-30BA3B模型,
Qwen3-VL-32B models,Qwen3-VL-32B模型,
Gemini-2.5-Flash,Gemini-2.5-Flash,
GPT-5-mini,GPT-5-mini,
long document understanding,长文档理解,
in-house dataset,内部数据集,
Ablation Study,消融研究,
CLIP,CLIP,
OmniBench,OmniBench,
Qwen3-ViT,Qwen3-ViT,
1.7B Qwen3 language model,1.7B Qwen3语言模型,
1.5T tokens,1.5T令牌,
SigLIP-2-based baseline,SigLIP-2基线,
instruct models,指令模型,
thinking models,思考模型,
Arena-Hard v2,Arena-Hard v2,
TAU2-Airline,TAU2-Airline,
TAU2-Telecom,TAU2-Telecom,
temperature,温度,
top-p,top-p,
top-k,top-k,
presence penalty,存在惩罚,
max output length,最大输出长度,
Mixture-of-Experts (MoE)architecture,专家混合架构,
GPT-4.1,GPT-4.1,
Claude3.7 Sonnet,Claude3.7 Sonnet,
Training Context,训练上下文,
40min,40分钟,
50min,50分钟,
60min,60分钟,
70min,70分钟,
80min,80分钟,
90min,90分钟,
100min,100分钟,
110min,110分钟,
120min,120分钟,
512k,512k,
768k,768k,
Runqi Qiao,乔润琪,
Qiuna Tan,谭启娜,
Guanting Dong,董冠廷,
Minhui Wu,吴明辉,
Chong Sun,孙崇,
Xiaoshuai Song,宋晓帅,
Zhuoma GongQue,龚曲卓玛,
Shanglin Lei,雷尚林,
Zhe Wei,魏哲,
Miaoxuan Zhang,张妙璇,
arXiv preprint arXiv:2407.01284,arXiv预印本arXiv:2407.01284,
2024,2024,
vision-language modeling (VLM),视觉语言建模,
Ablation on DeepStack,DeepStack消融实验,
internal 15B- A2B LLM,内部15B-A2B大语言模型,
200 billion tokens,2000亿token,
validation sets,验证集,
AVG,AVG,
OCRB,OCRB,
TVQA,TVQA,
RLWDQA,RLWDQA,
MM BEN,MM BEN,
MMBCN,MMBCN,
Baseline,基线,
Arena-Hard V2 (winrate) 12.0,Arena-Hard V2 (winrate) 12.0,
output length,输出长度,
Qwen3-235B-A22B-Instruct-2507,Qwen3-235B-A22B-Instruct-2507,
DeepSeek V3 0324,DeepSeek V3 0324,
Claude-Opus-4,Claude-Opus-4,
Claude-Opus-4 (with thinking),Claude-Opus-4 (带思考),
Table 5,表5,
Table 6,表6,
Large Language Models,大语言模型,
Vision Language model,视觉语言模型,
Table 7,表7,
Table 8,表8,
top-left corner,左上角,
bottom-right corner,右下角,
string,字符串,
object,对象,
Xianfu Cheng,程先福,
Wei Zhang,张伟,
Shiwei Zhang,张世伟,
Jian Yang,杨建,
Xiangyuan Guan,关祥元,
Xianjie Wu,吴先杰,
Xiang Li,李祥,
Ge Zhang,张格,
Jiaheng Liu,刘家恒,
Yuying Mai,麦宇莹,
Multimodal factuality evaluation,多模态事实性评估,
multimodal large language models,多模态大语言模型,
IEEE/CVF International Conference on Computer Vision,IEEE/CVF国际计算机视觉会议,
Xingyu Fu,付兴宇,
Yushi Hu,胡宇施,
Bangzheng Li,李邦正,
Yu Feng,冯宇,
Haoyu Wang,王浩宇,
Xudong Lin,林旭东,
Dan Roth,罗丹,
Noah A Smith,诺亚·A·史密斯,
Wei-Chiu Ma,马伟秋,
Ranjay Krishna,拉贾伊·克里希纳,
European Conference on Computer Vision,欧洲计算机视觉会议,
Chang Gao,高长,
Chujie Zheng,郑初杰,
Xiong-Hui Chen,陈雄辉,
Kai Dang,唐凯,
Shixuan Liu,刘世玄,
Bowen Yu,余 Bowen,
An Yang,杨安,
Shuai Bai,白帅,
Jingren Zhou,周景仁,
Junyang Lin,林俊阳,
Soft adaptive policy optimization,软自适应策略优化,
arXiv preprint arXiv:2511.20347,arXiv 预印本 arXiv:2511.20347,
Jiyang Gao,高继阳,
Chen Sun,孙晨,
Zhenheng Yang,杨振恒,
Ram Nevatia,Nevatia 拉姆,
Tall,Tall,
Temporal activity localization via language query,基于语言查询的时间活动定位,
Proceedings of the IEEE international conference on computer vision,IEEE 国际计算机视觉会议论文集,
Aryo Pradipta Gema,Aryo Pradipta Gema,
Joshua Ong Jun Leang,Joshua Ong Jun Leang,
Giwon Hong,Hong Giwon,
Alessio Devoto,Alessio Devoto,
Alberto Carlo Maria Mancino,Alberto Carlo Maria Mancino,
Rohit Saxena,Rohit Saxena,
Xuanli He,He Xuanli,
Yu Zhao,赵宇,
Xiaotang Du,杜晓堂,
Mohammad Reza Ghasemi Madani,Mohammad Reza Ghasemi Madani,
Claire Barale,Claire Barale,
Robert McHardy,Robert McHardy,
Joshua Harris,Joshua Harris,
Jean Kaddour,Jean Kaddour,
Emile van Krieken,Emile van Krieken,
Pasquale Minervini,Pasquale Minervini,
Are we done with mmlu?,我们完成 mmlu 吗？,
CoRR,CoRR,
abs/2406.04127,abs/2406.04127,
doi: 10.48550/ARXIV.2406.04127,doi: 10.48550/ARXIV.2406.04127,
URL https: //doi.org/10.48550/arXiv.2406.04127,URL https: //doi.org/10.48550/arXiv.2406.04127,
Tianrui Guan,关天瑞,
Fuxiao Liu,刘福晓,
Xiyang Wu,吴希阳,
Ruiqi Xian,先瑞琪,
Zongxia Li,李宗霞,
Xiaoyu Liu,刘晓宇,
Xijun Wang,王西军,
Lichang Chen,陈立昌,
Furong Huang,黄福荣,
Yaser Yacoob,Yaser Yacoob,
Dinesh Manocha,Dinesh Manocha,
Tianyi Zhou,周天毅,
advanced diagnostic suite,高级诊断套件,
entangled language hallucination & visual illusion,纠缠语言幻觉 & 视觉错觉,
large vision-language models,大视觉语言模型,
Yun He,何云,
Di Jin,金迪,
Chaoqi Wang,王超奇,
Chloe Bi,Chloe Bi,
Karishma Mandyam,Karishma Mandyam,
Hejia Zhang,张鹤佳,
Chen Zhu,朱晨,
Ning Li,李宁,
Tengyu Xu,徐腾宇,
Hongjiang Lv,吕洪江,
Shruti Bhosale,Shruti Bhosale,
Chenguang Zhu,朱晨光,
Karthik Abinav Sankararaman,Karthik Abinav Sankararaman,
Eryk Helenowski,Eryk Helenowski,
Melanie Kambadur,Melanie Kambadur,
Aditya Tayade,Aditya Tayade,
Hao Ma,马浩,
Han Fang,方汉,
Sinong Wang,王_sinong,
Multi-if,Multi-if,
Benchmarking llms on multi-turn and multilingual instructions following,在多轮和多语言指令遵循上基准测试 llms,
abs/2410.15553,abs/2410.15553,
doi: 10.48550/ ARXIV.2410.15553,doi: 10.48550/ ARXIV.2410.15553,
URL https://doi.org/10.48550/arXiv.2410.15553,URL https://doi.org/10.48550/arXiv.2410.15553,
HMMT,HMMT,
Hmmt 2025,Hmmt 2025,
https://www.hmmt.org,https://www.hmmt.org,
2025,2025,
